The netutil functions defined for `internal/util/netutil.go` will be POSIX-specific due to their reliance on concepts like FD_CLOEXEC and passing file descriptors across exec. If Windows support were ever a future requirement (though the current spec focuses on POSIX), these functions would need platform-specific implementations or stubs, likely managed with Go build tags (e.g., in files like `netutil_posix.go`, `netutil_windows.go`).
The `ImplementCurlHTTPClient` task will be complex, particularly parsing `curl` output reliably. Suggestion: use `curl` options to write headers and body to separate temporary files (e.g., `curl -D header_file -o body_file ...`) and then parse these files. Standard `curl` exit codes and `-w '%{http_code}'` can get status. This approach is generally more robust than parsing combined stdout/stderr from `curl -v` or `curl -i`.
StaticFileServer Test Plan Note:
Task_SFS_LoggingIntegration: An important aspect of testing the StaticFileServer is to verify its logging behavior. This is not listed as a separate, standalone task for a dedicated test function. Instead, each test case (e.g., for path errors, file serving, directory listing) should *also* incorporate checks for relevant log messages. This involves:
1.  Using a test logger (e.g., `logger.NewTestLogger` writing to a `bytes.Buffer`).
2.  After an operation, asserting that expected log messages (with correct levels and contextual fields like stream_id, path, error) are present in the buffer.
3.  Asserting that no unexpected error/critical logs appear for successful operations.
This ensures that the logging requirements of the StaticFileServer are met alongside its functional requirements.
The fix for FlowControlWindow.Acquire (to correctly block on negative window) is expected to address the h2spec failure:
`Hypertext Transfer Protocol Version 2 (HTTP/2) / 6. Frame Definitions / 6.9.2. Initial Flow-Control Window Size / 2: Sends a SETTINGS frame for window size to be negative`
  `-> The endpoint MUST track the negative flow-control window.`
  `Expected: DATA frame`
  `Actual: HEADERS Frame (length:77, flags:0x04, stream_id:1)`
Verifying this h2spec test passes after the change will be a key validation point.
The diagnostic changes made in `FlowControlWindow.Acquire` (Path Y, lines 88-104) to return specific error types like `StreamError` or `ConnectionError` instead of `fmt.Errorf` were intended to help trace if this specific error path was being hit and if the type of error returned was appropriate for upstream handlers. The goal is to ensure that errors from `Acquire` lead to correct termination of operations (e.g., stream reset) rather than unexpected behavior like sending premature HEADERS frames.

h2spec failures showing "Actual: HEADERS Frame" where "DATA frame" was expected, or timeouts, often point to issues where:
1. The server incorrectly closes a stream or its flow control window, preventing it from accepting valid subsequent frames (like WINDOW_UPDATE on a half-closed (remote) stream).
2. `FlowControlWindow.Acquire` does not block correctly (e.g., when the window is negative or insufficient), or returns an error that is mishandled, leading the server to send an erroneous HEADERS frame instead of waiting or sending DATA.
3. The server does not send WINDOW_UPDATE frames in a timely manner, causing the peer to stall (leading to DATA frame timeouts from the test client).
4. The server fails to process incoming DATA/HEADERS correctly due to internal errors (possibly related to flow control state), leading to no response or an incorrect response.
Objective: Fix h2spec failure "Sends invalid connection preface" where "connection reset by peer" is observed instead of "Connection closed".
Hypothesis: The `conn.Close()` method calls `c.initiateShutdown()` in a goroutine. If `conn.Close()` returns to its caller (e.g., `server.handleTCPConnection`) too quickly, the goroutine handling the TCP connection might exit. This could lead to the OS closing the underlying socket abruptly (TCP RST) before `initiateShutdown` has a chance to send the GOAWAY frame and perform a graceful FIN-based TCP close.

Proposed Change:
In `internal/http2/conn.go`, within the `Close` method, modify the call to `initiateShutdown`:
From: `go c.initiateShutdown(lastStreamID, goAwayErrorCode, debugData, gracefulTimeout)`
To:   `c.initiateShutdown(lastStreamID, goAwayErrorCode, debugData, gracefulTimeout)`

Rationale for Synchronous Call:
1.  **Guaranteed Completion:** `conn.Close()` will now block until `initiateShutdown` fully completes.
2.  **`initiateShutdown`'s Responsibilities:**
    *   Sends GOAWAY (queues to `writerChan`).
    *   Closes `shutdownChan` (signals reader/writer loops to stop).
    *   Closes `writerChan` (signals `writerLoop` to drain and exit).
    *   Waits for `writerLoop` to finish (`<-c.writerDone`). This ensures GOAWAY is written.
    *   Performs stream cleanup.
    *   **Crucially, closes `c.netConn` (the underlying TCP socket).**
    *   Cleans up other resources.
3.  **Preventing Premature Exit:** By making `initiateShutdown` synchronous, `c.netConn.Close()` (which performs the TCP FIN sequence) is guaranteed to be called before `conn.Close()` returns. This should give the OS time to handle the graceful TCP closure correctly.

Consideration of Existing Logic:
-   The `Close` method already has logic to wait for `readerDone` and `writerDone` *after* the (previously goroutined) `initiateShutdown` call. If `initiateShutdown` is now synchronous and itself ensures these are done (or signals them appropriately, e.g., `writerDone` is waited for, and `netConn.Close()` causes reader to exit and signal `readerDone`), these subsequent waits in `Close` will simply find the channels already closed, which is harmless.
-   Recursive or deferred calls to `Close()` (e.g., from timers or `writerLoop`'s defer) should still function correctly. If `initiateShutdown` is already running due to a primary `Close` call, subsequent `Close` calls will find `shutdownChan` closed and their `initiateShutdown` path will return early or simply wait, preventing problematic re-entrancy into the core shutdown logic.

This change directly targets the requirement of ensuring `initiateShutdown` completes before `Close` returns, which is believed to be the root cause of the TCP RST.
